{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatcrawler.crawler import Crawler\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "domain = 'ai.gov.ae'\n",
    "full_url = f'https://{domain}'\n",
    "\n",
    "crawler = Crawler(full_url)\n",
    "crawler.crawl()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_newlines(serie):\n",
    "    serie = serie.str.replace('\\n', ' ')\n",
    "    serie = serie.str.replace('\\\\n', ' ')\n",
    "    serie = serie.str.replace('  ', ' ')\n",
    "    serie = serie.str.replace('  ', ' ')\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# Create a list to store the text files\n",
    "texts=[]\n",
    "\n",
    "# Get all the text files in the text directory\n",
    "for file in os.listdir(\"text/\" + domain + \"/\"):\n",
    "    \n",
    "\n",
    "    # Open the file and read the text\n",
    "    with open(\"text/\" + domain + \"/\" + file, \"r\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "        # Omit the first 11 lines and the last 4 lines, then replace -, _, and #update with spaces.\n",
    "        texts.append((file[11:-4].replace('-',' ').replace('_', ' ').replace('#update',''), text))\n",
    "\n",
    "# Create a dataframe from the list of texts\n",
    "df = pd.DataFrame(texts, columns = ['fname', 'text'])\n",
    "\n",
    "# Set the text column to be the raw text with the newlines removed\n",
    "df['text'] = df.fname + \". \" + remove_newlines(df.text)\n",
    "df.to_csv('processed/scraped.csv', escapechar='\\\\')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Load the cl100k_base tokenizer which is designed to work with the ada-002 model\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "df = pd.read_csv('processed/scraped.csv', index_col=0)\n",
    "df.columns = ['title', 'text']\n",
    "\n",
    "# Tokenize the text and save the number of tokens to a new column\n",
    "df['n_tokens'] = df.text.apply(lambda x: len(tokenizer.encode(x)))\n",
    "\n",
    "# Visualize the distribution of the number of tokens per row using a histogram\n",
    "df.n_tokens.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 500\n",
    "\n",
    "# Function to split the text into chunks of a maximum number of tokens\n",
    "def split_into_many(text, max_tokens = max_tokens):\n",
    "\n",
    "    # Split the text into sentences\n",
    "    sentences = text.split('. ')\n",
    "\n",
    "    # Get the number of tokens for each sentence\n",
    "    n_tokens = [len(tokenizer.encode(\" \" + sentence)) for sentence in sentences]\n",
    "    \n",
    "    chunks = []\n",
    "    tokens_so_far = 0\n",
    "    chunk = []\n",
    "\n",
    "    # Loop through the sentences and tokens joined together in a tuple\n",
    "    for sentence, token in zip(sentences, n_tokens):\n",
    "\n",
    "        # If the number of tokens so far plus the number of tokens in the current sentence is greater \n",
    "        # than the max number of tokens, then add the chunk to the list of chunks and reset\n",
    "        # the chunk and tokens so far\n",
    "        if tokens_so_far + token > max_tokens:\n",
    "            chunks.append(\". \".join(chunk) + \".\")\n",
    "            chunk = []\n",
    "            tokens_so_far = 0\n",
    "\n",
    "        # If the number of tokens in the current sentence is greater than the max number of \n",
    "        # tokens, go to the next sentence\n",
    "        if token > max_tokens:\n",
    "            continue\n",
    "\n",
    "        # Otherwise, add the sentence to the chunk and add the number of tokens to the total\n",
    "        chunk.append(sentence)\n",
    "        tokens_so_far += token + 1\n",
    "\n",
    "    return chunks\n",
    "    \n",
    "\n",
    "shortened = []\n",
    "\n",
    "# Loop through the dataframe\n",
    "for row in df.iterrows():\n",
    "\n",
    "    # If the text is None, go to the next row\n",
    "    if row[1]['text'] is None:\n",
    "        continue\n",
    "\n",
    "    # If the number of tokens is greater than the max number of tokens, split the text into chunks\n",
    "    if row[1]['n_tokens'] > max_tokens:\n",
    "        shortened += split_into_many(row[1]['text'])\n",
    "    \n",
    "    # Otherwise, add the text to the list of shortened texts\n",
    "    else:\n",
    "        shortened.append( row[1]['text'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(shortened, columns = ['text'])\n",
    "df['n_tokens'] = df.text.apply(lambda x: len(tokenizer.encode(x)))\n",
    "df.n_tokens.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "df['embeddings'] = df.text.apply(lambda x: openai.Embedding.create(input=x, engine='text-embedding-ada-002')['data'][0]['embedding'])\n",
    "df.to_csv('processed/embeddings.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m openai\u001b[39m.\u001b[39mEmbedding\u001b[39m.\u001b[39mcreate(\u001b[39minput\u001b[39m\u001b[39m=\u001b[39mtext, engine\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtext-embedding-ada-002\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[39mwith\u001b[39;00m concurrent\u001b[39m.\u001b[39mfutures\u001b[39m.\u001b[39mThreadPoolExecutor() \u001b[39mas\u001b[39;00m executor:\n\u001b[0;32m----> 7\u001b[0m         embeddings \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(executor\u001b[39m.\u001b[39;49mmap(create_embedding, df[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m]))\n\u001b[1;32m      9\u001b[0m \u001b[39m# df['embeddings'] = embeddings\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# df.to_csv('processed/embeddings.csv')\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m# print(df.head())\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.10_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:621\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mwhile\u001b[39;00m fs:\n\u001b[1;32m    619\u001b[0m     \u001b[39m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    620\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39;49mpop())\n\u001b[1;32m    622\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39mpop(), end_time \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.10_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:319\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m         \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult(timeout)\n\u001b[1;32m    320\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m         fut\u001b[39m.\u001b[39mcancel()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.10_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.10_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from chatcrawler.logger import logger\n",
    "\n",
    "import concurrent.futures\n",
    "\n",
    "def create_embedding(text):\n",
    "    return openai.Embedding.create(input=text, engine='text-embedding-ada-002')['data'][0]['embedding']\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    embeddings = []\n",
    "    for i, result in enumerate(executor.map(create_embedding, df['text'])):\n",
    "        embeddings.append(result)\n",
    "        logger.info(\"Processed %d/%d texts\", i+1, len(df))\n",
    "\n",
    "# df['embeddings'] = embeddings\n",
    "# df.to_csv('processed/embeddings.csv')\n",
    "# print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai.embeddings_utils import distances_from_embeddings, cosine_similarity\n",
    "\n",
    "df=pd.read_csv('processed/embeddings.csv', index_col=0)\n",
    "df['embeddings'] = df['embeddings'].apply(eval).apply(np.array)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context(\n",
    "    question, df, max_len=1800, size=\"ada\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a context for a question by finding the most similar context from the dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the embeddings for the question\n",
    "    q_embeddings = openai.Embedding.create(input=question, engine='text-embedding-ada-002')['data'][0]['embedding']\n",
    "\n",
    "    # Get the distances from the embeddings\n",
    "    df['distances'] = distances_from_embeddings(q_embeddings, df['embeddings'].values, distance_metric='cosine')\n",
    "\n",
    "\n",
    "    returns = []\n",
    "    cur_len = 0\n",
    "\n",
    "    # Sort by distance and add the text to the context until the context is too long\n",
    "    for i, row in df.sort_values('distances', ascending=True).iterrows():\n",
    "        \n",
    "        # Add the length of the text to the current length\n",
    "        cur_len += row['n_tokens'] + 4\n",
    "        \n",
    "        # If the context is too long, break\n",
    "        if cur_len > max_len:\n",
    "            break\n",
    "        \n",
    "        # Else add it to the text that is being returned\n",
    "        returns.append(row[\"text\"])\n",
    "\n",
    "    # Return the context\n",
    "    return \"\\n\\n###\\n\\n\".join(returns)\n",
    "\n",
    "def answer_question(\n",
    "    df,\n",
    "    model=\"text-davinci-003\",\n",
    "    question=\"Am I allowed to publish model outputs to Twitter, without a human review?\",\n",
    "    max_len=1800,\n",
    "    size=\"ada\",\n",
    "    debug=False,\n",
    "    max_tokens=150,\n",
    "    stop_sequence=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Answer a question based on the most similar context from the dataframe texts\n",
    "    \"\"\"\n",
    "    context = create_context(\n",
    "        question,\n",
    "        df,\n",
    "        max_len=max_len,\n",
    "        size=size,\n",
    "    )\n",
    "    # If debug, print the raw model response\n",
    "    if debug:\n",
    "        print(\"Context:\\n\" + context)\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    try:\n",
    "        # Create a completions using the question and context\n",
    "        response = openai.Completion.create(\n",
    "            prompt=f\"Answer the question based on the context below, and if the question can't be answered based on the context, say \\\"I don't know\\\"\\n\\nContext: {context}\\n\\n---\\n\\nQuestion: {question}\\nAnswer:\",\n",
    "            temperature=0,\n",
    "            max_tokens=max_tokens,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=stop_sequence,\n",
    "            model=model,\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_question(df, question=\"What day is it?\", debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_question(df, question=\"What is our newest embeddings model?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05f34a34d73b71652304030c1097be3a5720ea2447153dd6542d145a26b73181"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
